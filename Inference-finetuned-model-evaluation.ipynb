{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a870983-bd44-4c06-bc1f-f413719002c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-18 08:07:33 nemo_logging:361] /app/src/pyenv/lib/python3.10/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "      warnings.warn(\"Can't initialize NVML\")\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-18 08:07:39 mixins:181] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-18 08:07:40 modelPT:181] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: ../data/springlab-asr-task-wavs/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 4\n",
      "    shuffle: true\n",
      "    trim_silence: true\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    normalize_transcripts: true\n",
      "    \n",
      "[NeMo W 2025-07-18 08:07:40 modelPT:188] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: ../data/springlab-asr-task-wavs/validation_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 4\n",
      "    shuffle: false\n",
      "    normalize_transcripts: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-18 08:07:41 features:305] PADDING: 0\n",
      "[NeMo I 2025-07-18 08:07:52 rnnt_models:226] Using RNNT Loss : tdt\n",
      "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n",
      "[NeMo I 2025-07-18 08:07:52 rnnt_models:226] Using RNNT Loss : tdt\n",
      "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-18 08:07:52 label_looping_base:109] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-18 08:07:52 rnnt_models:226] Using RNNT Loss : tdt\n",
      "    Loss tdt_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0, 'durations': [0, 1, 2, 3, 4], 'sigma': 0.02, 'omega': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-18 08:07:52 label_looping_base:109] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-18 08:07:53 save_restore_connector:282] Model EncDecRNNTBPEModel was successfully restored from /app/src/model/parakeet-spring-lab-asr-task-wavs-finetuned/parakeet_finetuned.nemo.\n"
     ]
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "\n",
    "fine_tuned_model = \"./models/parakeet-spring-lab-asr-task-wavs-finetuned/parakeet_finetuned.nemo\"\n",
    "\n",
    "asr_model = nemo_asr.models.ASRModel.restore_from(restore_path=fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebfe0fc3-3cb2-46d3-b84e-a6fc59fb36f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing:   0%|                                                                                                                     | 0/1 [00:00<?, ?it/s][NeMo W 2025-07-18 08:07:53 nemo_logging:361] /app/src/pyenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "      warnings.warn(warn_msg)\n",
      "    \n",
      "Transcribing: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well i dont wish to see it any more observed pebe turning away her eyes it is certainly very like the old portrait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "audio_file_path = \"../data/2086-149220-0033.wav\"\n",
    "\n",
    "output = asr_model.transcribe([audio_file_path])\n",
    "print(output[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bfe1137-21ae-4e85-881e-12af78a95ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/springlab-asr-task-wavs/test_manifest.json\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a713cff-dd6c-4a3d-89e4-4f0ff9135010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio_filepath': '/app/data/springlab-asr-task-wavs/test_audio_0.wav',\n",
       " 'duration': 6.41,\n",
       " 'text': 'systems spectral technology enables the development of new mobile applications'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46db7f23-fc3c-4263-b36f-2a4ac19b771d",
   "metadata": {},
   "source": [
    "### Multiple Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9f0827c-559a-47ae-ba5d-bf43b2194dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_test_manifest(manifest_path):\n",
    "    \"\"\"Load test manifest and return list of samples\"\"\"\n",
    "    samples = []\n",
    "    \n",
    "    print(f\"Loading test manifest from: {manifest_path}\")\n",
    "    \n",
    "    with open(manifest_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:  # Skip empty lines\n",
    "                try:\n",
    "                    sample = json.loads(line)\n",
    "                    samples.append(sample)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error parsing line: {line}\")\n",
    "                    print(f\"Error: {e}\")\n",
    "    \n",
    "    print(f\"Loaded {len(samples)} samples from manifest\")\n",
    "    return samples\n",
    "\n",
    "def inference_with_manifest(model_path, manifest_path):\n",
    "    \"\"\"Inference using test manifest with ground truth comparison\"\"\"\n",
    "    \n",
    "    print(f\"Loading fine-tuned model from: {model_path}\")\n",
    "    asr_model = nemo_asr.models.ASRModel.restore_from(restore_path=model_path)\n",
    "    print(\"Model loaded successfully!\")\n",
    "    \n",
    "\n",
    "    test_samples = load_test_manifest(manifest_path)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Process each sample from manifest\n",
    "    print(\"Starting inference with ground truth comparison...\")\n",
    "    \n",
    "    for sample in tqdm(test_samples, desc=\"Processing test samples\"):\n",
    "        # Extract information from manifest\n",
    "        audio_filepath = sample.get('audio_filepath', '')\n",
    "        original_text = sample.get('text', '')\n",
    "        duration = sample.get('duration', 0)\n",
    "        \n",
    "        # Get filename for reference\n",
    "        filename = os.path.basename(audio_filepath)\n",
    "\n",
    "        output = asr_model.transcribe([audio_filepath])\n",
    "        predicted_text = output[0].text\n",
    "        \n",
    "        \n",
    "        # Store result with comparison\n",
    "        result = {\n",
    "            \"filename\": filename,\n",
    "            \"audio_filepath\": audio_filepath,\n",
    "            \"original_text\": original_text,\n",
    "            \"predicted_text\": predicted_text,\n",
    "            \"duration\": duration\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "698db4e9-2122-4bbf-831c-f77ba78bd39f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "\n",
    "fine_tuned_model = \"./models/parakeet-spring-lab-asr-task-wavs-finetuned/parakeet_finetuned.nemo\"\n",
    "\n",
    "test_manifest_path = \"../data/springlab-asr-task-wavs/test_manifest.json\"\n",
    "\n",
    "total_results = inference_with_manifest(model_path = fine_tuned_model, manifest_path = test_manifest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0fc7c1-a0e8-41cf-a6af-98b5b94a3d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# output_dir = \"../data/springlab-asr-task-wavs-test-data-v1.json\"\n",
    "\n",
    "# with open(output_dir, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(total_results, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d26d46-0fb7-467f-bec6-384553dbd2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6bffbe3-9dbb-4dea-9f46-2d7ded07e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "output_dir = \"../data/springlab-asr-task-wavs-test-data-v1.json\"\n",
    "\n",
    "with open(output_dir, 'r', encoding='utf-8') as f:\n",
    "    loaded_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78dccb89-dcf5-404c-be5f-ac0c350d8cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': 'test_audio_0.wav',\n",
       " 'audio_filepath': '/app/data/springlab-asr-task-wavs/test_audio_0.wav',\n",
       " 'original_text': 'systems spectral technology enables the development of new mobile applications',\n",
       " 'predicted_text': 'system spectral technology enables the development of new mobile applications',\n",
       " 'duration': 6.41}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dcd4a3-f28c-4792-9300-f1e3f620e853",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7299af2-a51a-4898-b5b6-9730b540b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d61db3-5a7e-46f7-849a-4bdcda6eff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(ref: List[str], hyp: List[str]) -> int:\n",
    "    \"\"\"Calculate edit distance between two sequences\"\"\"\n",
    "    d = [[0] * (len(hyp) + 1) for _ in range(len(ref) + 1)]\n",
    "    \n",
    "    for i in range(len(ref) + 1):\n",
    "        d[i][0] = i\n",
    "    for j in range(len(hyp) + 1):\n",
    "        d[0][j] = j\n",
    "    \n",
    "    for i in range(1, len(ref) + 1):\n",
    "        for j in range(1, len(hyp) + 1):\n",
    "            if ref[i-1] == hyp[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "            else:\n",
    "                d[i][j] = min(d[i-1][j], d[i][j-1], d[i-1][j-1]) + 1\n",
    "    \n",
    "    return d[len(ref)][len(hyp)]\n",
    "\n",
    "def word_error_rate(reference: str, hypothesis: str) -> float:\n",
    "    \"\"\"Calculate Word Error Rate\"\"\"\n",
    "    ref_words = reference.strip().split()\n",
    "    hyp_words = hypothesis.strip().split()\n",
    "    \n",
    "    if len(ref_words) == 0:\n",
    "        return 0.0 if len(hyp_words) == 0 else 1.0\n",
    "    \n",
    "    errors = edit_distance(ref_words, hyp_words)\n",
    "    return errors / len(ref_words)\n",
    "\n",
    "def character_error_rate(reference: str, hypothesis: str) -> float:\n",
    "    \"\"\"Calculate Character Error Rate (excluding spaces)\"\"\"\n",
    "    ref_chars = list(reference.replace(' ', ''))\n",
    "    hyp_chars = list(hypothesis.replace(' ', ''))\n",
    "    \n",
    "    if len(ref_chars) == 0:\n",
    "        return 0.0 if len(hyp_chars) == 0 else 1.0\n",
    "    \n",
    "    errors = edit_distance(ref_chars, hyp_chars)\n",
    "    return errors / len(ref_chars)\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Normalize text for comparison\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def calculate_and_save_metrics(loaded_data: List[Dict], output_file: str):\n",
    "    \"\"\"\n",
    "    Calculate WER and CER for each sample and save to CSV\n",
    "    \n",
    "    Args:\n",
    "        loaded_data: List of dictionaries with 'original_text' and 'predicted_text' keys\n",
    "        output_file: Output CSV filename\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Processing {len(loaded_data)} samples...\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, item in enumerate(loaded_data):\n",
    "        # Get original texts (non-normalized for display)\n",
    "        original_text = item['original_text']\n",
    "        predicted_text = item['predicted_text']\n",
    "        \n",
    "        # Normalize for calculation\n",
    "        original_normalized = normalize_text(original_text)\n",
    "        predicted_normalized = normalize_text(predicted_text)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        wer = word_error_rate(original_normalized, predicted_normalized)\n",
    "        cer = character_error_rate(original_normalized, predicted_normalized)\n",
    "        \n",
    "        # Store result\n",
    "        results.append({\n",
    "            'original_text': original_text,\n",
    "            'predicted_text': predicted_text,\n",
    "            'CER': round(cer, 4),\n",
    "            'WER': round(wer, 4)\n",
    "        })\n",
    "        \n",
    "        # Print progress\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(loaded_data)} samples\")\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calculate_and_save_with_filename(loaded_data: List[Dict], output_file: str):\n",
    "    \"\"\"\n",
    "    Calculate WER and CER for each sample and save to CSV (includes filename if available)\n",
    "    \n",
    "    Args:\n",
    "        loaded_data: List of dictionaries with 'original_text' and 'predicted_text' keys\n",
    "        output_file: Output CSV filename\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Processing {len(loaded_data)} samples...\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, item in enumerate(loaded_data):\n",
    "        # Get original texts (non-normalized for display)\n",
    "        original_text = item['original_text']\n",
    "        predicted_text = item['predicted_text']\n",
    "        filename = item.get('filename', f'sample_{i}')\n",
    "        \n",
    "        # Normalize for calculation\n",
    "        original_normalized = normalize_text(original_text)\n",
    "        predicted_normalized = normalize_text(predicted_text)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        wer = word_error_rate(original_normalized, predicted_normalized)\n",
    "        cer = character_error_rate(original_normalized, predicted_normalized)\n",
    "        \n",
    "        # Store result\n",
    "        results.append({\n",
    "            'filename': filename,\n",
    "            'original_text': original_text,\n",
    "            'predicted_text': predicted_text,\n",
    "            'CER': round(cer, 4),\n",
    "            'WER': round(wer, 4)\n",
    "        })\n",
    "        \n",
    "        # Print progress\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(loaded_data)} samples\")\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    \n",
    "    # Print summary statistics\n",
    "    avg_wer = df['WER'].mean()\n",
    "    avg_cer = df['CER'].mean()\n",
    "    \n",
    "    print(f\"\\nResults saved to: {output_file}\")\n",
    "    print(f\"Summary Statistics:\")\n",
    "    print(f\"  Average WER: {avg_wer:.4f} ({avg_wer*100:.2f}%)\")\n",
    "    print(f\"  Average CER: {avg_cer:.4f} ({avg_cer*100:.2f}%)\")\n",
    "    print(f\"  Total samples: {len(results)}\")\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd9fa5e2-4cc0-4c6d-bd15-2cc016a5d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir1 = \"../data/springlab-asr-task-wavs-test-data-v1.json\"\n",
    "\n",
    "with open(output_dir1, 'r', encoding='utf-8') as f:\n",
    "    loaded_data1 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92c0b4ac-0fe5-4627-afde-72301620c2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 800 samples...\n",
      "Processed 100/800 samples\n",
      "Processed 200/800 samples\n",
      "Processed 300/800 samples\n",
      "Processed 400/800 samples\n",
      "Processed 500/800 samples\n",
      "Processed 600/800 samples\n",
      "Processed 700/800 samples\n",
      "Processed 800/800 samples\n",
      "\n",
      "Results saved to: ../data/springlab-asr-task-wavs-test-data-v1-wer_cer_results.csv\n",
      "Summary Statistics:\n",
      "  Average WER: 0.1091 (10.91%)\n",
      "  Average CER: 0.0500 (5.00%)\n",
      "  Total samples: 800\n",
      "\n",
      "CSV file created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # data\n",
    "    example_data = loaded_data1\n",
    "    \n",
    "    filename = \"../data/springlab-asr-task-wavs-test-data-v1-wer_cer_results.csv\"\n",
    "    # Save results to CSV\n",
    "    df = calculate_and_save_with_filename(example_data, output_file = filename)\n",
    "    \n",
    "    print(\"\\nCSV file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "745f6084-3c03-4a49-95ad-e448d97ccb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average WER: 0.1091 (10.91%)\n",
      "Average CER: 0.0500 (5.00%)\n",
      "Total samples: 800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/springlab-asr-task-wavs-test-data-v1-wer_cer_results.csv')\n",
    "\n",
    "avg_wer = df['WER'].mean()\n",
    "avg_cer = df['CER'].mean()\n",
    "\n",
    "print(f\"Average WER: {avg_wer:.4f} ({avg_wer*100:.2f}%)\")\n",
    "print(f\"Average CER: {avg_cer:.4f} ({avg_cer*100:.2f}%)\")\n",
    "print(f\"Total samples: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca086ed8-cdbd-485a-99ac-4c2ca1adc2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
